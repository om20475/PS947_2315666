---
title: 'PS947: Homework 3'
author: "Oishika Mukherjee "
GIT_link: "https://github.com/om20475/PS947_2315666"
date: "01/03/2024 "
output:
  html_document:
    df_print: paged
  word_document: default
  pdf_document: default
---

```{r, echo=TRUE, include=FALSE,warning=FALSE}
#------------ Adding required libraries -----------#



library('dplyr')
library('ggplot2')
library('tidyverse')
library(car)
library(ggthemes)
library(RColorBrewer)
library(wesanderson)
library(lme4)

set.seed(42)
```

```{r,echo = True, warning=FALSE}
#read in recommendations.csv#
recommendations <- read.csv(file.choose())

# excluding the index column
recommendations <- subset(recommendations, select = -X)
```

```{r,echo = True, warning=FALSE}
# Converting the categorical columns to factors
recommendations$Mode <- as.factor(recommendations$Mode)
recommendations$Gender <- as.factor(recommendations$Gender)
recommendations$Stimulus <- as.factor(recommendations$Stimulus)
recommendations$RecommendationFollowed <- as.factor(recommendations$RecommendationFollowed)
```

#--------- Answer 2.1 --------------#

```{r,echo = True, warning=FALSE}

# Fit the model
model <- glm(RecommendationFollowed ~ Mode, family = binomial, data = recommendations)
summary(model)
```

**Summary Explanation**:- The "ModeVisual" is the estimated difference in log-odds between the modes i.e. "Auditory" and "Visual". From the "Estimate" coefficient of "ModeVisual" we can say that the log-odds of accepting the recommendation(RecommendationFollowed) being 1 decreases by 0.4858 when going from "auditory" to "Visual". Again, in our case, the p-value for "ModeVisual" is 1.95e-06, which is much less than 0.05, indicating a statistically significant difference in recommendation acceptance between auditory and visual modes. The decrease in deviance values when switching from the null model to our suggested model also suggests that "recommendationMode" is useful for predicting recommendation followed.

In conclusion, the model suggests that there is a difference in recommendations followed by the two modes. The negative coefficient for ModeVisual suggests that the recommendations followed is lower for Visual mode compared to Auditory mode.

**Analysis Choice Explanation**:- We have used the "glm" model of "binomial" family because the outcome variable (RecommendationFollowed) is binary (0 or 1) in nature. The model predicts the probability of a binary outcome(Recommendation accepted or rejected) based on one or more predictor variables.

#--------- Answer 2.2 --------------#

```{r,echo = True, include=TRUE,warning=FALSE}
# Plot the data
ggplot(recommendations, aes(x = Mode, fill = RecommendationFollowed)) +
  geom_bar(position = "fill") +
  ylab("Proportion") +
  xlab("Recommendation Mode") +
  ggtitle("Proportion of Recommendations Followed by Mode") +
  theme_few()

```

**Explanation**:- We can observe that the proportion of RecommendationFollowed is around 0.52 or 52% when the Recommendation mode is Auditory, whereas the same for Visual mode is around 39-40 %. Therefore, it is evident that the participants usually follow more recommendations when the recommendation mode is Auditory rather than visual. Another interesting fact is that in more than half of the cases(nearly 60%) participants rejected the recommendation when the mode is visual.

#--------- Answer 2.3 --------------#

```{r,echo = True, warning=FALSE}
# Fit the model
model2 <- glm(RecommendationFollowed ~ Mode + Mode * CompositeIntellect, family = binomial, data = recommendations)
summary(model2)

```

**Explanation**:- In order to analyse the effects of competency, intelligence, and thoughtfulness with modality, we have included the variable "CompositeIntellect" as it represents the composite measure of perceived competence, intelligence, and thoughtfulness(The average of 3 scores). Including "CompositeIntellect" variable in our revised 'glm' model along with an interaction term between "CompositeIntellect" and "Mode" would allow us to examine if the effect of perceived intellect varies depending on the recommendation mode.

The model suggests that the Mode of Visual and CompositeIntellect significantly affect whether the Recommendation is followed. When the Mode is Visual, the log odds of RecommendationFollowed decrease by 0.1669. On the other hand, for each unit increase in CompositeIntellect, the log odds of RecommendationFollowed increase by 0.4430. In our revised 'glm' model, the corresponding p-value for CompositeIntellect is less than 2e-16 , i.e. much less than 0.05 which suggests that the 'compositeintellect' is statistically significant and plays a crucial role whether the recommendation is perceived or not. However, the interaction term ModeVisual:CompositeIntellect is not statistically significant(P value \> 0), indicating that the effect of Mode on RecommendationFollowed does not depend on CompositeIntellect.

Therefore we can conclude that the compositeIntellect(competent, intelligent and/or thoughtful) and Mode of recommendations are important factors over accepting or declining a recommendation individually.

#--------- Answer 3.1 --------------#

The beta distribution takes two shape parameters i.e. alpha and beta. These parameters are responsible for controlling the shape of the distribution. Both parameters must be positive in value.

The Beta distribution is defined in the interval \[0, 1\], therefore we need to scale the dependent variable i.e students' marks to be within this range.

#--------- Answer 3.2 --------------#

```{r,echo=TRUE, include=TRUE,warning=FALSE}

# Define parameters
alpha <- 30
beta <- 15

# creating data
x <- seq(0, 1, 0.01)
y <- dbeta(x, alpha, beta)

# Creating dataframe
df <- data.frame(x = x, y = y)

# Plot
ggplot(df, aes(x = x, y = y)) +
  geom_line() +
  theme_minimal() +
  labs(x = "Marks (scaled)", y = "Density", title = "Beta Distribution")


```

Comparing with the given example in the slide where mu is given as N(67,5), we set our alpha and beta as 30 and 15 through trial and error method. In our case the informative prior is centered around 0.67

#--------- Answer 3.3 --------------#

```{r,echo=TRUE, include=TRUE,warning=FALSE}

# Define parameters for weakly informative priors
weak_alpha <- 7
weak_beta <- 7

# Define parameters for weakly informative priors
alpha <- 80
beta <- 50

# creating marks data
x <- seq(0, 1, 0.01)

# Creating dataframe with beta distribution information
beta_informative <- dbeta(x, weak_alpha,weak_beta )
beta_weak <- dbeta(x, alpha, beta)
data <- data.frame(x,beta_informative, beta_weak)
#data

ggplot(data) + geom_line(aes(x, beta_informative),color='red') + geom_line(aes(x, beta_weak), color = 'blue')+labs(x = "Probability", y = "Y", title = "Beta Distribution for Informative and Weakly Informative priors")

```

The red line denotes the Beta distribution for Weakly informative priors whereas the blue line suggests the beta distribution for informative priors. The Beta distribution for weakly informative priors is widely spread around the mean probability 0.5 as we have chosen "7" as both alpha and beta parameter values.

For the informative priors, we have set the parameter values as 80 (alpha) and 50 (beta) for the beta distribution. Here, we are assuming that the pass mark as 50 and highest gained mark as 80.

#--------- Answer 3.4 --------------#

```{r,echo=TRUE, include=TRUE,warning=FALSE}
# Generate priors
priors <- tibble(n = 1:50) %>% 
  group_by(n) %>% 
  mutate(alpha = runif(1,65,85), beta = runif(1,40,50))
priors

# Define function to generate prior predictions
gen_prior_pred <- function(n, alpha, beta) {
  x <- seq(0, 1, 0.01)
  d <- tibble(n = n, alpha = alpha, beta = beta,
              x = x,
              y = dbeta(x, alpha, beta))
  return(d)
}

# Apply function to each prior sample
prior_ll <- pmap_df(priors, gen_prior_pred)

```

```{r}
# Plot the results
ggplot(prior_ll, aes(x, y, group = interaction(alpha, beta))) + 
  geom_path() +
  labs(x = "Probability", y = "Probability Density", 
       title = "Prior Predictions for Beta Distributions")
```

We have plotted a set of prior predictions for our Beta distribution. For the alpha parameter, we have generated a set of values using a normal distribution ranging from 65 to 85, assuming that the upper range of marks falls within this interval. Similarly, for Beta, we have generated a set of values distributed normally within the range of 40 to 50, which we assume represents the minimum obtained marks.
